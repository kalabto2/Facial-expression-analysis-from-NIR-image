{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85c33a91",
   "metadata": {},
   "source": [
    "# Creating data splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937546e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## create-unpaired_casia_oulu-casia_data\n",
    "### Create unpaired split\n",
    "From Oulu-Casia and Casia2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb162e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Specify the directories\n",
    "nir_path = Path('data/CASIA_NISVIR/NIR-VIS/NIR/')\n",
    "vis_path = Path('data/CASIA_NISVIR/NIR-VIS/VIS/')\n",
    "\n",
    "# Get the contents of the directories\n",
    "nir_images = list(nir_path.glob('*.bmp'))  # replace with your image extension\n",
    "vis_images = list(vis_path.glob('*.jpg'))  # replace with your image extension\n",
    "\n",
    "# Determine the size of the smaller dataset\n",
    "min_size = min(len(nir_images), len(vis_images))\n",
    "\n",
    "# Randomly select 'min_size' images from both NIR and VIS datasets\n",
    "nir_images_selected = random.sample(nir_images, min_size)\n",
    "vis_images_selected = random.sample(vis_images, min_size)\n",
    "\n",
    "# Get the images that are not selected\n",
    "nir_images_unselected = list(set(nir_images) - set(nir_images_selected))\n",
    "vis_images_unselected = list(set(vis_images) - set(vis_images_selected))\n",
    "\n",
    "# Split the NIR images into train, val, and test sets\n",
    "nir_train_val, nir_test = train_test_split(nir_images_selected, test_size=0.2, random_state=42)\n",
    "nir_train, nir_val = train_test_split(nir_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Split the VIS images into train, val, and test sets\n",
    "vis_train_val, vis_test = train_test_split(vis_images_selected, test_size=0.2, random_state=42)\n",
    "vis_train, vis_val = train_test_split(vis_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Convert the Path objects to strings\n",
    "nir_train = [str(path) for path in nir_train]\n",
    "nir_val = [str(path) for path in nir_val]\n",
    "nir_test = [str(path) for path in nir_test]\n",
    "vis_train = [str(path) for path in vis_train]\n",
    "vis_val = [str(path) for path in vis_val]\n",
    "vis_test = [str(path) for path in vis_test]\n",
    "nir_images_unselected = [str(path) for path in nir_images_unselected]\n",
    "vis_images_unselected = [str(path) for path in vis_images_unselected]\n",
    "\n",
    "# Prepare the metadata\n",
    "metadata = {\n",
    "    'nir_images_selected': len(nir_images_selected),\n",
    "    'vis_images_selected': len(vis_images_selected),\n",
    "    'nir_images_unselected': len(nir_images_unselected),\n",
    "    'vis_images_unselected': len(vis_images_unselected),\n",
    "    'nir_train': len(nir_train),\n",
    "    'nir_val': len(nir_val),\n",
    "    'nir_test': len(nir_test),\n",
    "    'vis_train': len(vis_train),\n",
    "    'vis_val': len(vis_val),\n",
    "    'vis_test': len(vis_test),\n",
    "}\n",
    "\n",
    "# Prepare the data to be stored in the JSON file\n",
    "data = {\n",
    "    'nir_train': nir_train,\n",
    "    'nir_val': nir_val,\n",
    "    'nir_test': nir_test,\n",
    "    'nir_rest': nir_images_unselected,\n",
    "    'vis_train': vis_train,\n",
    "    'vis_val': vis_val,\n",
    "    'vis_test': vis_test,\n",
    "    'vis_rest': vis_images_unselected,\n",
    "    'metadata': metadata,\n",
    "}\n",
    "\n",
    "# Write the data to the JSON file\n",
    "with open('splits/new/casia2_data_splits.json', 'w') as f:\n",
    "    json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a287b6b4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from skeleton.data.splitter import DatasetSplitter\n",
    "import json\n",
    "import os\n",
    "\n",
    "# define splitter\n",
    "splitter = DatasetSplitter(\n",
    "    vl_data_path=Path('data/B_OriginalImg/VL/Strong/'),\n",
    "    ni_data_path=Path('data/B_OriginalImg/NI/Strong/'),\n",
    "    train_n_img_picked=5,\n",
    "    test_n_img_picked=2,\n",
    "    val_n_img_picked=2,\n",
    "    json_train_split_pth=Path('_train_tmp.json'),\n",
    "    json_test_split_pth=Path('_test_tmp.json'),\n",
    "    json_val_split_pth=Path('_val_tmp.json'),\n",
    ")\n",
    "\n",
    "# split the files\n",
    "splitter()\n",
    "\n",
    "\n",
    "# Load the temporary JSON files\n",
    "with open('_train_tmp.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "with open('_test_tmp.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "with open('_val_tmp.json', 'r') as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "# Prepare the metadata\n",
    "metadata = {\n",
    "    'nir_images': len(train_data['ni']) + len(test_data['ni']) + len(val_data['ni']),\n",
    "    'vis_images': len(train_data['vl']) + len(test_data['vl']) + len(val_data['vl']),\n",
    "    'nir_train': len(train_data['ni']),\n",
    "    'nir_val': len(val_data['ni']),\n",
    "    'nir_test': len(test_data['ni']),\n",
    "    'vis_train': len(train_data['vl']),\n",
    "    'vis_val': len(val_data['vl']),\n",
    "    'vis_test': len(test_data['vl']),\n",
    "}\n",
    "\n",
    "# Prepare the data to be stored in the JSON file\n",
    "data = {\n",
    "    'nir_train': train_data['ni'],\n",
    "    'nir_val': val_data['ni'],\n",
    "    'nir_test': test_data['ni'],\n",
    "    'vis_train': train_data['vl'],\n",
    "    'vis_val': val_data['vl'],\n",
    "    'vis_test': test_data['vl'],\n",
    "    'metadata': metadata,\n",
    "}\n",
    "\n",
    "# Write the data to the JSON file\n",
    "with open('splits/new/oulucasia_data_splits.json', 'w') as f:\n",
    "    json.dump(data, f)\n",
    "\n",
    "# Remove the temporary files\n",
    "os.remove('_train_tmp.json')\n",
    "os.remove('_test_tmp.json')\n",
    "os.remove('_val_tmp.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c5844",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load the existing data from the two files\n",
    "with open('splits/new/casia2_data_splits.json', 'r') as f:\n",
    "    casia2_data = json.load(f)\n",
    "with open('splits/new/oulucasia_data_splits.json', 'r') as f:\n",
    "    oulucasia_data = json.load(f)\n",
    "\n",
    "# Merge the data\n",
    "merged_data = {}\n",
    "for key in set(casia2_data.keys()).union(oulucasia_data.keys()):\n",
    "    if key != 'metadata':\n",
    "        merged_data[key] = casia2_data.get(key, []) + oulucasia_data.get(key, [])\n",
    "\n",
    "# Merge the metadata\n",
    "merged_metadata = {}\n",
    "for key in set(casia2_data['metadata'].keys()).union(oulucasia_data['metadata'].keys()):\n",
    "    merged_metadata[key] = casia2_data['metadata'].get(key, 0) + oulucasia_data['metadata'].get(key, 0)\n",
    "\n",
    "# Add the merged metadata to the merged data\n",
    "merged_data['metadata'] = merged_metadata\n",
    "\n",
    "# Save the merged data back to the file\n",
    "with open('splits/new/merged_data_splits.json', 'w') as f:\n",
    "    json.dump(merged_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106aaa8f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7badeb73",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import os\n",
    "import click\n",
    "import cv2\n",
    "\n",
    "from deepface import DeepFace\n",
    "\n",
    "\n",
    "class FacePreprocessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_split_pth,\n",
    "        test_split_pth,\n",
    "        val_split_pth,\n",
    "        new_train_vl_pth,\n",
    "        new_train_ni_pth,\n",
    "        new_test_vl_pth,\n",
    "        new_test_ni_pth,\n",
    "        new_val_ni_pth,\n",
    "        new_val_vl_pth,\n",
    "        detector_backend,\n",
    "        target_size,\n",
    "        new_train_split_pth=None,\n",
    "        new_test_split_pth=None,\n",
    "        new_val_split_pth=None,\n",
    "    ):\n",
    "        self.train_split_pth = train_split_pth\n",
    "        self.test_split_pth = test_split_pth\n",
    "        self.val_split_pth = val_split_pth\n",
    "        self.new_train_vl_pth = new_train_vl_pth\n",
    "        self.new_train_ni_pth = new_train_ni_pth\n",
    "        self.new_test_vl_pth = new_test_vl_pth\n",
    "        self.new_test_ni_pth = new_test_ni_pth\n",
    "        self.new_val_ni_pth = new_val_ni_pth\n",
    "        self.new_val_vl_pth = new_val_vl_pth\n",
    "        self.detector_backend = detector_backend\n",
    "        self.target_size = target_size\n",
    "        self.new_train_split = new_train_split_pth\n",
    "        self.new_test_split = new_test_split_pth\n",
    "        self.new_val_split = new_val_split_pth\n",
    "\n",
    "    def detect_and_align_face(self, image_fp):\n",
    "        try:\n",
    "            face_objs = DeepFace.extract_faces(\n",
    "                img_path=image_fp,\n",
    "                target_size=self.target_size,\n",
    "                detector_backend=self.detector_backend,\n",
    "                enforce_detection=False,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR at {image_fp}\", e)\n",
    "            return None\n",
    "\n",
    "        if len(face_objs) != 1:\n",
    "            print(\"NOT FOUND OR MULTIPLE FACES!\")\n",
    "            return None\n",
    "\n",
    "        face = face_objs[0][\"face\"]\n",
    "\n",
    "        return face\n",
    "\n",
    "    def preprocess_part(self, fps, target_fp, spectra):\n",
    "        # prepare filepath\n",
    "        os.makedirs(target_fp, exist_ok=True)\n",
    "\n",
    "        # align faces for all images\n",
    "        i = 0\n",
    "        preprocessed_fps = []\n",
    "        for fp in fps:\n",
    "            new_filename = \"-\".join(pathlib.PurePath(fp).parts[-3:])\n",
    "            target_path = os.path.join(target_fp, new_filename)\n",
    "\n",
    "            aligned_face = self.detect_and_align_face(fp)\n",
    "\n",
    "            if aligned_face is None:\n",
    "                continue\n",
    "\n",
    "            aligned_face = 255 * aligned_face[:, :, ::-1]\n",
    "\n",
    "            cv2.imwrite(target_path, aligned_face)\n",
    "\n",
    "            print(f\"#{i} {spectra} Stored: {new_filename}\")\n",
    "            i += 1\n",
    "            preprocessed_fps.append(target_path)\n",
    "\n",
    "        return preprocessed_fps\n",
    "\n",
    "    def preprocess_split(self, split_pth, new_vl_path, new_ni_pth):\n",
    "        with open(split_pth, \"r\") as f:\n",
    "            paths = json.load(f)\n",
    "\n",
    "        vl_preproc_fps = self.preprocess_part(paths[\"vl\"], new_vl_path, \"vl\")\n",
    "        ni_preproc_fps = self.preprocess_part(paths[\"ni\"], new_ni_pth, \"ni\")\n",
    "\n",
    "        return {\"vl\": vl_preproc_fps, \"ni\": ni_preproc_fps}\n",
    "\n",
    "    def preprocess(self):\n",
    "#         preprocess train split\n",
    "        train_fps = self.preprocess_split(\n",
    "            self.train_split_pth, self.new_train_vl_pth, self.new_train_ni_pth\n",
    "        )\n",
    "\n",
    "        if self.new_train_split:\n",
    "            with open(self.new_train_split, \"w\") as f:\n",
    "                json.dump(train_fps, f)\n",
    "\n",
    "        # preprocess test split\n",
    "        test_fps = self.preprocess_split(\n",
    "            self.test_split_pth, self.new_test_vl_pth, self.new_test_ni_pth\n",
    "        )\n",
    "\n",
    "        if self.new_test_split:\n",
    "            with open(self.new_test_split, \"w\") as f:\n",
    "                json.dump(test_fps, f)\n",
    "\n",
    "        # preprocess val split\n",
    "        val_fps = self.preprocess_split(\n",
    "            self.val_split_pth, self.new_val_vl_pth, self.new_val_ni_pth\n",
    "        )\n",
    "\n",
    "        if self.new_val_split:\n",
    "            with open(self.new_val_split, \"w\") as f:\n",
    "                json.dump(val_fps, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70084ee3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('splits/new/merged_data_splits.json') as f:\n",
    "    merged_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614afbce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('_train_split_tmp.json', 'w') as f:\n",
    "    json.dump({'ni': merged_data['nir_train'], 'vl': merged_data['vis_train']}, f)\n",
    "with open('_test_split_tmp.json', 'w') as f:\n",
    "    json.dump({'ni': merged_data['nir_test'], 'vl': merged_data['vis_test']}, f)\n",
    "with open('_val_split_tmp.json', 'w') as f:\n",
    "    json.dump({'ni': merged_data['nir_val'], 'vl': merged_data['vis_val']}, f)\n",
    "\n",
    "preprocessor = FacePreprocessor(\n",
    "    train_split_pth='_train_split_tmp.json',\n",
    "    test_split_pth='_test_split_tmp.json',\n",
    "    val_split_pth='_val_split_tmp.json',\n",
    "    new_train_vl_pth='data/casia-oulucasia-unpaired/A/train',\n",
    "    new_train_ni_pth='data/casia-oulucasia-unpaired/B/train',\n",
    "    new_test_vl_pth='data/casia-oulucasia-unpaired/A/test',\n",
    "    new_test_ni_pth='data/casia-oulucasia-unpaired/B/test',\n",
    "    new_val_vl_pth='data/casia-oulucasia-unpaired/A/val',\n",
    "    new_val_ni_pth='data/casia-oulucasia-unpaired/B/val',\n",
    "    detector_backend='retinaface',\n",
    "    target_size=(224, 224),\n",
    "    new_train_split_pth='splits/new/preproc-merged-train',\n",
    "    new_test_split_pth='splits/new/preproc-merged-test',\n",
    "    new_val_split_pth='splits/new/preproc-merged-val',\n",
    ")\n",
    "\n",
    "preprocessor.preprocess()\n",
    "               \n",
    "os.remove('_train_split_tmp.json')\n",
    "os.remove('_test_split_tmp.json')\n",
    "os.remove('_val_split_tmp.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ce4aae",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "merged_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ed6253",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create-buaa-w_and_wo_stripes-train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26e77dc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from deepface import DeepFace\n",
    "from skeleton.inference import CenterFace\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "__DATA_FOLDER = 'data/BUAA/BUAAVISNIR/'\n",
    "__TARGET_SIZE = (224, 224)\n",
    "__TARGET_FOLDER = 'data/buaa-w_and_wo_stripes-train_test/'\n",
    "\n",
    "centerface = CenterFace()\n",
    "\n",
    "\n",
    "def fill_black(image):\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    max_dim = max([width, height])\n",
    "\n",
    "    black_image = np.zeros((max_dim, max_dim, image.shape[-1]), dtype=np.uint8)\n",
    "\n",
    "    width_padding = max_dim - width\n",
    "    height_padding = max_dim - height\n",
    "    y1 = int(height_padding/2)\n",
    "    y2 = int(max_dim - height_padding/2)\n",
    "    x1 = int(width_padding/2)\n",
    "    x2 = int(max_dim - width_padding/2)\n",
    "\n",
    "    black_image[y1:y2, x1:x2, :] = image\n",
    "\n",
    "    return black_image\n",
    "\n",
    "\n",
    "def operation_X(image_pth_A, image_pth_B):\n",
    "    # load\n",
    "    image_np_A = cv2.imread(str(image_pth_A))\n",
    "    image_np_A = cv2.cvtColor(image_np_A, cv2.COLOR_BGR2RGB)\n",
    "    image_np_B = cv2.imread(str(image_pth_B))\n",
    "    image_np_B = cv2.cvtColor(image_np_B, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # expects 3 channels\n",
    "    if image_np_A.shape[2] == 1:\n",
    "        image_np_A = np.concatenate([image_np_A] * 3, axis=-1)\n",
    "\n",
    "    # predict\n",
    "    dets, lms = centerface(image_np_A, threshold=0.35)\n",
    "\n",
    "    det = dets[0]\n",
    "    width = det[2] - det[0]\n",
    "    height = det[3] - det[1]\n",
    "    bigger_dimension = max([width, height])\n",
    "    width_padding = bigger_dimension - width\n",
    "    height_padding = bigger_dimension - height\n",
    "\n",
    "    face_A = image_np_A[int(det[1]-width_padding//2):int(det[3]+width_padding//2),\n",
    "                        int(det[0]-width_padding//2):int(det[2]+width_padding//2), :]\n",
    "    face_B = image_np_B[int(det[1]-width_padding//2):int(det[3]+width_padding//2),\n",
    "                        int(det[0]-width_padding//2):int(det[2]+width_padding//2), :]\n",
    "\n",
    "    face_A = cv2.resize(face_A, __TARGET_SIZE)\n",
    "    face_B = cv2.resize(face_B, __TARGET_SIZE).astype(np.uint8)\n",
    "    face_A_np = np.mean(face_A, axis=2)\n",
    "    face_A = np.stack([face_A_np, face_A_np, face_A_np],\n",
    "                      axis=2).astype(np.uint8)\n",
    "\n",
    "    display(Image.fromarray(np.concatenate([face_A, face_B], axis=1)))\n",
    "\n",
    "    return face_A, face_B\n",
    "\n",
    "\n",
    "def operation_Y(image_pth_A, image_pth_B):\n",
    "    face_objs_A = DeepFace.extract_faces(\n",
    "        img_path=image_pth_A,\n",
    "        target_size=__TARGET_SIZE,\n",
    "        detector_backend=\"retinaface\",\n",
    "        enforce_detection=False,\n",
    "        align=False\n",
    "    )\n",
    "\n",
    "    face_B_np = np.mean(cv2.imread(image_pth_B), axis=2)\n",
    "    face_B_np = np.stack([face_B_np, face_B_np, face_B_np], axis=2)\n",
    "\n",
    "    face_A = (face_objs_A[0]['face'] * 255).astype(np.uint8)\n",
    "    ar = face_objs_A[0]['facial_area']\n",
    "    face_B = face_B_np[ar['y']:ar['y']+ar['h'], ar['x']:ar['x']+ar['w']]\n",
    "\n",
    "    face_B = fill_black(face_B)\n",
    "    face_B = cv2.resize(face_B, __TARGET_SIZE).astype(np.uint8)\n",
    "\n",
    "    face_A_np = np.mean(face_A, axis=2)\n",
    "    face_A = np.stack([face_A_np, face_A_np, face_A_np],\n",
    "                      axis=2).astype(np.uint8)\n",
    "\n",
    "    display(Image.fromarray(np.concatenate([face_A, face_B], axis=1)))\n",
    "\n",
    "    return face_A, face_B\n",
    "\n",
    "\n",
    "# Get the list of patient ids\n",
    "patient_ids = [name for name in os.listdir(\n",
    "    __DATA_FOLDER) if os.path.isdir(os.path.join(__DATA_FOLDER, name))]\n",
    "\n",
    "# Split the patient ids into train, validation, and test sets\n",
    "train_ids, test_ids = train_test_split(\n",
    "    patient_ids, test_size=0.2, random_state=42)\n",
    "# train_ids, val_ids = train_test_split(train_ids, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "\n",
    "# Function to process and save images\n",
    "def process_and_save_images(ids, split):\n",
    "    filepaths_A = []\n",
    "    filepaths_B = []\n",
    "    invalid = []\n",
    "    for _id in sorted(ids):\n",
    "        patient_folder = os.path.join(__DATA_FOLDER, _id)\n",
    "        dir_content = [i for i in os.listdir(\n",
    "            patient_folder) if i[-3:] == 'bmp']\n",
    "        image_files = sorted(dir_content, key=lambda x: int(\n",
    "            x.split('.')[0]))  # Sort the files to ensure pairs\n",
    "        image_files = [i for i in image_files if int(i.split('.')[0]) <= 28]\n",
    "        for file_A, file_B in zip(image_files[0::2], image_files[1::2]):\n",
    "            print(str(os.path.join(patient_folder, file_A)),\n",
    "                  str(os.path.join(patient_folder, file_B)))\n",
    "\n",
    "            img_path_A = os.path.join(patient_folder, file_A)\n",
    "            img_path_B = os.path.join(patient_folder, file_B)\n",
    "\n",
    "            try:\n",
    "                if random.choice([True, False]):\n",
    "                    img_A, img_B = operation_X(img_path_A, img_path_B)\n",
    "                else:\n",
    "                    img_A, img_B = operation_Y(img_path_A, img_path_B)\n",
    "            except:\n",
    "                invalid.append(img_path_A)\n",
    "                continue\n",
    "\n",
    "            # Save the images\n",
    "            Image.fromarray(img_A).save(\n",
    "                os.path.join(split + 'A', f'{_id}_{file_A}'))\n",
    "            Image.fromarray(img_B).save(\n",
    "                os.path.join(split + 'B', f'{_id}_{file_B}'))\n",
    "\n",
    "            filepaths_A.append(\n",
    "                str(os.path.join(split + 'A', f'{_id}_{file_A}')))\n",
    "            filepaths_B.append(\n",
    "                str(os.path.join(split + 'B', f'{_id}_{file_B}')))\n",
    "\n",
    "    return filepaths_A, filepaths_B, invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aea8fa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Process and save images for each split\n",
    "out_train = process_and_save_images(train_ids, __TARGET_FOLDER + 'train')\n",
    "# out_val = process_and_save_images(val_ids, __TARGET_FOLDER + 'val')\n",
    "out_test = process_and_save_images(test_ids, __TARGET_FOLDER + 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6242c1df",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## AffectNet prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e79434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T22:04:25.815184Z",
     "start_time": "2023-12-14T22:04:25.797468Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7640dd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T22:37:17.608892Z",
     "start_time": "2023-12-14T22:37:17.551353Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('splits/new/merged_data_splits.json', 'r') as f:\n",
    "    casia_oulucasia_split = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381da06c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T22:07:19.912480Z",
     "start_time": "2023-12-14T22:07:19.809171Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load the existing data from the two files\n",
    "with open('splits/new/casia2_data_splits.json', 'r') as f:\n",
    "    casia2_data = json.load(f)\n",
    "with open('splits/new/oulucasia_data_splits.json', 'r') as f:\n",
    "    oulucasia_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a184a4bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T22:08:18.422147Z",
     "start_time": "2023-12-14T22:08:18.402987Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Merge the data\n",
    "merged_data = {}\n",
    "for key in set(casia2_data.keys()).union(oulucasia_data.keys()):\n",
    "    if key != 'metadata':\n",
    "        merged_data[key] = casia2_data.get(key, []) + oulucasia_data.get(key, [])\n",
    "\n",
    "# Merge the metadata\n",
    "merged_metadata = {}\n",
    "for key in set(casia2_data['metadata'].keys()).union(oulucasia_data['metadata'].keys()):\n",
    "    merged_metadata[key] = casia2_data['metadata'].get(key, 0) + oulucasia_data['metadata'].get(key, 0)\n",
    "\n",
    "# Add the merged metadata to the merged data\n",
    "merged_data['metadata'] = merged_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dd95d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T22:37:47.804515Z",
     "start_time": "2023-12-14T22:37:47.772870Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "merged_data['nir_rest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d43dc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T22:48:33.575743Z",
     "start_time": "2023-12-14T22:48:33.555111Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import os\n",
    "import click\n",
    "import cv2\n",
    "\n",
    "from deepface import DeepFace\n",
    "\n",
    "\n",
    "def detect_and_align_face(image_fp):\n",
    "    try:\n",
    "        face_objs = DeepFace.extract_faces(\n",
    "            img_path=image_fp,\n",
    "            target_size=(256, 256),\n",
    "            detector_backend=\"retinaface\",\n",
    "            enforce_detection=False,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR at {image_fp}\", e)\n",
    "        return None\n",
    "\n",
    "    if len(face_objs) != 1:\n",
    "        print(\"NOT FOUND OR MULTIPLE FACES!\")\n",
    "        return None\n",
    "\n",
    "    face = face_objs[0][\"face\"]\n",
    "\n",
    "    return face\n",
    "\n",
    "def preprocess_part( fps, target_fp, spectra):\n",
    "    # prepare filepath\n",
    "    os.makedirs(target_fp, exist_ok=True)\n",
    "\n",
    "    # align faces for all images\n",
    "    i = 0\n",
    "    preprocessed_fps = []\n",
    "    for fp in fps:\n",
    "        new_filename = \"-\".join(pathlib.PurePath(fp).parts[-3:])\n",
    "        target_path = os.path.join(target_fp, new_filename)\n",
    "\n",
    "        aligned_face = detect_and_align_face(fp)\n",
    "\n",
    "        if aligned_face is None:\n",
    "            continue\n",
    "\n",
    "        aligned_face = 255 * aligned_face[:, :, ::-1]\n",
    "\n",
    "        cv2.imwrite(target_path, aligned_face)\n",
    "\n",
    "        print(f\"#{i} {spectra} Stored: {new_filename}\")\n",
    "        i += 1\n",
    "        preprocessed_fps.append(target_path)\n",
    "\n",
    "    return preprocessed_fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43d6ef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T02:55:09.602755Z",
     "start_time": "2023-12-14T22:48:56.470674Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preproc_casia_fps = preprocess_part(merged_data['nir_rest'], \"data/for_unpaired-casia_preprocessed_rest_of_NIR/\", \"NIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6830d30c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T22:38:57.933689Z",
     "start_time": "2023-12-14T22:38:57.662322Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "__BUAA_PREPROC_FOLDER = 'data/Z_PreprocImg-BUAA-centerface-gray-averaged/BUAAVISNIR'\n",
    "\n",
    "buaa_nir_images = []\n",
    "for root, dirs, files in os.walk(__BUAA_PREPROC_FOLDER):\n",
    "    for file in files:\n",
    "        if int(file.split('.')[0]) % 2 == 0:\n",
    "            buaa_nir_images.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76071802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T22:39:08.670933Z",
     "start_time": "2023-12-14T22:39:08.660078Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buaa_nir_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e999e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T22:39:10.606139Z",
     "start_time": "2023-12-14T22:39:10.246218Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "__AFFECTNET_PREPROC_TRAIN_FOLDER = 'data/AffectNet-8Labels/train_set/images'\n",
    "\n",
    "retrieve_frist_n_images = len(buaa_nir_images) + len(merged_data['nir_rest'])\n",
    "affectnet_vis_images = []\n",
    "for i, f_nms in enumerate(sorted(os.listdir(__AFFECTNET_PREPROC_TRAIN_FOLDER), key=lambda x: int(x.split('.')[0]))):\n",
    "    if i > retrieve_frist_n_images:\n",
    "        break\n",
    "    affectnet_vis_images.append(os.path.join(__AFFECTNET_PREPROC_TRAIN_FOLDER, f_nms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b738e76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T22:39:10.791535Z",
     "start_time": "2023-12-14T22:39:10.758692Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "affectnet_vis_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7c63d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T17:26:55.487297Z",
     "start_time": "2023-12-15T17:26:55.475418Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "a = [0.,0.5]\n",
    "print(a)\n",
    "\n",
    "x = math.sqrt(a[0]*a[0] + a[1]*a[1])\n",
    "print(\"radius\", x, \"-\", \"in\" if x <=1 else \"out\")\n",
    "r = 1 - x\n",
    "print(\"rest to boundary\", r)\n",
    "enl = 1/(1 - a[0])\n",
    "print(\"enlarge\", enl)\n",
    "print([a[0]*enl, a[1]*enl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26416f24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T22:39:13.031459Z",
     "start_time": "2023-12-14T22:39:12.998421Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.mkdir('data/unpaired_additional_train-affectnet_vis_and_buaa_casia_nir', )\n",
    "os.mkdir('data/unpaired_additional_train-affectnet_vis_and_buaa_casia_nir/vis', )\n",
    "os.mkdir('data/unpaired_additional_train-affectnet_vis_and_buaa_casia_nir/nir', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d93b34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T09:46:29.067675Z",
     "start_time": "2023-12-15T09:45:01.321069Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for i, (vis_pth, nir_pth) in enumerate(zip(affectnet_vis_images, buaa_nir_images + preproc_casia_fps)):\n",
    "#     vis_new_fp = 'data/unpaired_additional_train-affectnet_vis_and_buaa_casia_nir/vis/' + \"affnet-\" + vis_pth.split('/')[-1]\n",
    "    nir_new_fp = 'data/unpaired_additional_train-affectnet_vis_and_buaa_casia_nir/nir/' + \"buaa-casia-\" + str(i) + \".\" + (nir_pth.split('/')[-1]).split('.')[-1]\n",
    "    \n",
    "#     shutil.copyfile(vis_pth, vis_new_fp)\n",
    "    shutil.copyfile(nir_pth, nir_new_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8096edc3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "merged_data['nir_rest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8ae322",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvDIP",
   "language": "python",
   "name": "venvdip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

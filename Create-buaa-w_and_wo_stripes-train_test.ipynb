{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a431a952",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5be036f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T19:23:54.581349Z",
     "start_time": "2023-12-19T19:23:20.241772Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 20:23:27.304807: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-19 20:23:27.357979: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-19 20:23:27.358923: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-19 20:23:34.272846: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from deepface import DeepFace\n",
    "from skeleton.inference import CenterFace\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "__DATA_FOLDER = 'data/BUAA/BUAAVISNIR/'\n",
    "__TARGET_SIZE = (224, 224)\n",
    "__TARGET_FOLDER = 'data/buaa-w_and_wo_stripes-train_test/'\n",
    "\n",
    "centerface = CenterFace()\n",
    "\n",
    "\n",
    "def fill_black(image):\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    max_dim = max([width, height])\n",
    "    \n",
    "    black_image = np.zeros((max_dim, max_dim, image.shape[-1]), dtype=np.uint8)\n",
    "    \n",
    "    width_padding = max_dim - width\n",
    "    height_padding = max_dim - height\n",
    "    y1 = int(height_padding/2)\n",
    "    y2 = int(max_dim - height_padding/2)\n",
    "    x1 = int(width_padding/2)\n",
    "    x2 = int(max_dim - width_padding/2)\n",
    "    \n",
    "    black_image[y1:y2,x1:x2,:] = image\n",
    "    \n",
    "    return black_image\n",
    "    \n",
    "def operation_X(image_pth_A, image_pth_B):\n",
    "    # load \n",
    "    image_np_A = cv2.imread(str(image_pth_A))\n",
    "    image_np_A = cv2.cvtColor(image_np_A, cv2.COLOR_BGR2RGB)\n",
    "    image_np_B = cv2.imread(str(image_pth_B))\n",
    "    image_np_B = cv2.cvtColor(image_np_B, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # expects 3 channels\n",
    "    if image_np_A.shape[2] == 1:\n",
    "        image_np_A = np.concatenate([image_np_A] * 3, axis=-1)\n",
    "    \n",
    "    # predict\n",
    "    dets, lms = centerface(image_np_A, threshold=0.35)\n",
    "    \n",
    "    det = dets[0]\n",
    "    width = det[2] - det[0]\n",
    "    height = det[3] - det[1]\n",
    "    bigger_dimension= max([width,height])\n",
    "    width_padding = bigger_dimension - width\n",
    "    height_padding = bigger_dimension - height\n",
    "    \n",
    "    face_A = image_np_A[int(det[1]-width_padding//2):int(det[3]+width_padding//2), \\\n",
    "                 int(det[0]-width_padding//2):int(det[2]+width_padding//2),:]\n",
    "    face_B = image_np_B[int(det[1]-width_padding//2):int(det[3]+width_padding//2), \\\n",
    "                 int(det[0]-width_padding//2):int(det[2]+width_padding//2),:]\n",
    "        \n",
    "    face_A = cv2.resize(face_A, __TARGET_SIZE)\n",
    "    face_B = cv2.resize(face_B, __TARGET_SIZE).astype(np.uint8)\n",
    "    face_A_np = np.mean(face_A, axis=2)\n",
    "    face_A = np.stack([face_A_np,face_A_np,face_A_np], axis=2).astype(np.uint8)\n",
    "    \n",
    "    display(Image.fromarray(np.concatenate([face_A, face_B], axis=1)))\n",
    "        \n",
    "    return face_A, face_B\n",
    "    \n",
    "\n",
    "def operation_Y(image_pth_A, image_pth_B):    \n",
    "    face_objs_A = DeepFace.extract_faces(\n",
    "        img_path=image_pth_A,\n",
    "        target_size=__TARGET_SIZE,\n",
    "        detector_backend=\"retinaface\",\n",
    "        enforce_detection=False,\n",
    "        align=False\n",
    "    )\n",
    "\n",
    "    face_B_np = np.mean(cv2.imread(image_pth_B), axis=2)\n",
    "    face_B_np = np.stack([face_B_np,face_B_np,face_B_np], axis=2)\n",
    "    \n",
    "    face_A = (face_objs_A[0]['face'] * 255).astype(np.uint8)\n",
    "    ar = face_objs_A[0]['facial_area']\n",
    "    face_B = face_B_np[ar['y']:ar['y']+ar['h'], ar['x']:ar['x']+ar['w']]\n",
    "    \n",
    "    face_B = fill_black(face_B)\n",
    "    face_B = cv2.resize(face_B, __TARGET_SIZE).astype(np.uint8)\n",
    "    \n",
    "    face_A_np = np.mean(face_A, axis=2)\n",
    "    face_A = np.stack([face_A_np,face_A_np,face_A_np], axis=2).astype(np.uint8)\n",
    "    \n",
    "    display(Image.fromarray(np.concatenate([face_A, face_B], axis=1)))\n",
    "        \n",
    "    return face_A, face_B\n",
    "\n",
    "# Get the list of patient ids\n",
    "patient_ids = [name for name in os.listdir(__DATA_FOLDER) if os.path.isdir(os.path.join(__DATA_FOLDER, name))]\n",
    "\n",
    "# Split the patient ids into train, validation, and test sets\n",
    "train_ids, test_ids = train_test_split(patient_ids, test_size=0.2, random_state=42)\n",
    "# train_ids, val_ids = train_test_split(train_ids, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "\n",
    "\n",
    "# Function to process and save images\n",
    "def process_and_save_images(ids, split):\n",
    "    filepaths_A = []\n",
    "    filepaths_B = []\n",
    "    invalid = []\n",
    "    for _id in sorted(ids):\n",
    "        patient_folder = os.path.join(__DATA_FOLDER, _id)\n",
    "        dir_content = [i for i in os.listdir(patient_folder) if i[-3:] == 'bmp']\n",
    "        image_files = sorted(dir_content, key=lambda x: int(x.split('.')[0]))  # Sort the files to ensure pairs\n",
    "        image_files = [i for i in image_files if int(i.split('.')[0]) <= 28]\n",
    "        for file_A, file_B in zip(image_files[0::2], image_files[1::2]):\n",
    "            print(str(os.path.join(patient_folder, file_A)), str(os.path.join(patient_folder, file_B)))\n",
    "            \n",
    "            img_path_A = os.path.join(patient_folder, file_A)\n",
    "            img_path_B = os.path.join(patient_folder, file_B)\n",
    "        \n",
    "            try:\n",
    "                if random.choice([True, False]):\n",
    "                    img_A, img_B = operation_X(img_path_A, img_path_B)\n",
    "                else:\n",
    "                    img_A, img_B = operation_Y(img_path_A, img_path_B)\n",
    "            except:\n",
    "                invalid.append(img_path_A)\n",
    "                continue\n",
    "                \n",
    "            \n",
    "            # Save the images\n",
    "            Image.fromarray(img_A).save(os.path.join(split + 'A', f'{_id}_{file_A}'))\n",
    "            Image.fromarray(img_B).save(os.path.join(split + 'B', f'{_id}_{file_B}'))\n",
    "            \n",
    "            filepaths_A.append(str(os.path.join(split + 'A', f'{_id}_{file_A}')))\n",
    "            filepaths_B.append(str(os.path.join(split + 'B', f'{_id}_{file_B}')))\n",
    "            \n",
    "    return filepaths_A, filepaths_B,invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e64b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T19:59:29.328921Z",
     "start_time": "2023-12-19T19:23:54.583511Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Process and save images for each split\n",
    "out_train = process_and_save_images(train_ids, __TARGET_FOLDER + 'train')\n",
    "# out_val = process_and_save_images(val_ids, __TARGET_FOLDER + 'val')\n",
    "out_test = process_and_save_images(test_ids, __TARGET_FOLDER + 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de99b9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvDIP",
   "language": "python",
   "name": "venvdip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

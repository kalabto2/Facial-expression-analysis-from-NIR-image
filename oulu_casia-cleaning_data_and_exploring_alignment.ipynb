{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4ffbf2f",
   "metadata": {},
   "source": [
    "# Data cleaning of OuluCasia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528cc4e0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Clean badly paired images - rate their pair quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcfb8ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T20:00:05.754326Z",
     "start_time": "2023-12-06T10:27:48.665449Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root_dir1 = 'data/B_OriginalImg/NI/Strong/'\n",
    "root_dir2 = 'data/B_OriginalImg/VL/Strong/'\n",
    "\n",
    "# Initialize a dictionary to store the ratings and directories\n",
    "ratings = {}\n",
    "# Initialize a list to store the unpaired images\n",
    "unpaired_images = []\n",
    "\n",
    "# Initialize a variable to store the previous pair\n",
    "prev_pair = None\n",
    "\n",
    "rate_em = None\n",
    "\n",
    "# Loop over patient directories\n",
    "for i, patient_dir in enumerate(sorted(os.listdir(root_dir1))):\n",
    "    patient_path1 = os.path.join(root_dir1, patient_dir)\n",
    "    patient_path2 = os.path.join(root_dir2, patient_dir)\n",
    "    \n",
    "    if i < 50:\n",
    "        continue\n",
    "    \n",
    "    # Loop over emotion directories\n",
    "    for emotion_dir in sorted(os.listdir(patient_path1)):\n",
    "        emotion_path1 = os.path.join(patient_path1, emotion_dir)\n",
    "        emotion_path2 = os.path.join(patient_path2, emotion_dir)\n",
    "        \n",
    "        # Loop over images\n",
    "        for image_file in sorted(os.listdir(emotion_path1)):\n",
    "            image_path1 = os.path.join(emotion_path1, image_file)\n",
    "            image_path2 = os.path.join(emotion_path2, image_file)\n",
    "            \n",
    "            key = f\"{patient_dir}-{emotion_dir}-{image_file}\"\n",
    "            \n",
    "            if rate_em is not None:\n",
    "                ratings[key] = (rate_em, image_path1, image_path2)\n",
    "                continue\n",
    "            \n",
    "            # Check if the image has a pair in the second directory\n",
    "            if os.path.exists(image_path2):\n",
    "                # Open the image from the first directory\n",
    "                image1 = Image.open(image_path1)\n",
    "                \n",
    "                # Open the image from the second directory\n",
    "                image2 = Image.open(image_path2)\n",
    "                \n",
    "                while True:\n",
    "                    # Create a subplot with 1 row and 2 columns\n",
    "                    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "                    \n",
    "                    # Display the image from the first directory\n",
    "                    axs[0].imshow(image1)\n",
    "                    axs[0].set_title(f'First Directory - {patient_dir} - {emotion_dir} - {image_file}')\n",
    "                    \n",
    "                    # Display the image from the second directory\n",
    "                    axs[1].imshow(image2)\n",
    "                    axs[1].set_title(f'Second Directory - {patient_dir} - {emotion_dir} - {image_file}')\n",
    "                    \n",
    "                    # Show the plot\n",
    "                    plt.show()\n",
    "                    \n",
    "                    # Get the user's rating\n",
    "                    rating = input(\"Rate the quality of pairing from 1 (great) to 5 (worst). Press 'x' to continue to the next pair of images. Press 'r' to go back to the previous pair.\")\n",
    "                    \n",
    "                    if rating in ['1', '2', '3', '4', '5']:\n",
    "                        # Store the rating and directories\n",
    "                        ratings[key] = (rating, image_path1, image_path2)\n",
    "                        prev_pair = key\n",
    "                        break\n",
    "                    elif rating == 'd':\n",
    "                        for im in sorted(os.listdir(emotion_path1)):\n",
    "                            im1 = os.path.join(emotion_path1, im)\n",
    "                            im2 = os.path.join(emotion_path2, im)\n",
    "                            \n",
    "                            if im[-4:] != 'jpeg' or not os.path.exists(im2):\n",
    "                                continue\n",
    "                            \n",
    "\n",
    "                            \n",
    "                            # Open the image from the first directory\n",
    "                            img1 = Image.open(im1)\n",
    "\n",
    "                            # Open the image from the second directory\n",
    "                            img2 = Image.open(im2)\n",
    "                            \n",
    "                            # Create a subplot with 1 row and 2 columns\n",
    "                            fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "                            \n",
    "                            # Display the image from the first directory\n",
    "                            axs[0].imshow(img1)\n",
    "                            axs[0].set_title(f'First Directory - {patient_dir} - {emotion_dir} - {im}')\n",
    "\n",
    "                            # Display the image from the second directory\n",
    "                            axs[1].imshow(img2)\n",
    "                            axs[1].set_title(f'Second Directory - {patient_dir} - {emotion_dir} - {im}')\n",
    "\n",
    "                            # Show the plot\n",
    "                            plt.show()\n",
    "                    elif rating in ['e1', 'e2','e3', 'e4', 'e5']:\n",
    "                        ratings[key] = (rating[1], image_path1, image_path2)\n",
    "                        prev_pair = key\n",
    "                        rate_em = rating[1]\n",
    "                        break\n",
    "                    elif rating == 'r' and prev_pair is not None:\n",
    "                        # Go back to the previous pair\n",
    "                        patient_dir, emotion_dir, image_file = prev_pair.split('-')\n",
    "                        image_path1 = ratings[prev_pair][1]\n",
    "                        image_path2 = ratings[prev_pair][2]\n",
    "                        image1 = Image.open(image_path1)\n",
    "                        image2 = Image.open(image_path2)\n",
    "                    else:\n",
    "                        print(\"Invalid input. Please enter a number from 1 to 5, 'x' to continue, or 'r' to go back.\")\n",
    "            else:\n",
    "                # Log the unpaired image\n",
    "                unpaired_images.append(image_path1)\n",
    "        \n",
    "        rate_em = None\n",
    "        \n",
    "    # Save the ratings and unpaired images to a JSON file\n",
    "    with open('ratings_pt5.json', 'w') as f:\n",
    "        json.dump({'ratings': ratings, 'unpaired_images': unpaired_images}, f)\n",
    "\n",
    "# Print a summary of the ratings\n",
    "print(\"Summary of ratings:\")\n",
    "summary = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "for rating, _ in ratings.values():\n",
    "    summary[int(rating)] += 1\n",
    "for rating, count in summary.items():\n",
    "    print(f\"Number of pairs with rating {rating}: {count}\")\n",
    "\n",
    "print(\"Unpaired images:\")\n",
    "for image in unpaired_images:\n",
    "    print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc85e57d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Extract faces from cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d03a28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T00:17:46.513685Z",
     "start_time": "2023-12-08T17:29:14.875107Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from deepface import DeepFace\n",
    "\n",
    "with open('ratings_merged_first_place.json') as f:\n",
    "    rat_dict = json.load(f)\n",
    "\n",
    "for rating, a, b in list(ratings.values()):\n",
    "    if a[-2:] == 'db':\n",
    "        continue\n",
    "    if int(rating) == 1:\n",
    "        im_a = cv2.imread(a)\n",
    "        im_b = cv2.imread(b)\n",
    "        \n",
    "        print(a)\n",
    "        print(b)\n",
    "        if im_a is None or im_b is None:\n",
    "            continue\n",
    "        \n",
    "        im_b = cv2.cvtColor(im_b, cv2.COLOR_BGR2RGB)\n",
    "        im_ext_b = DeepFace.extract_faces(im_b, (224, 224), detector_backend='retinaface', align=True, enforce_detection=True)\n",
    "        im_ext_a = DeepFace.extract_faces(im_a, (224, 224), detector_backend='retinaface', align=True, enforce_detection=True)\n",
    "        im_ext_b = (255 * im_ext_b[0]['face']).astype(np.uint8)\n",
    "        im_ext_a = (255 * im_ext_a[0]['face']).astype(np.uint8)\n",
    "        \n",
    "        cv2.imwrite('data/oulucasia-ranked-aligned/trainA/' + '-'.join(a.split('/')[-3:]), im_ext_a)\n",
    "        cv2.imwrite('data/oulucasia-ranked-aligned/trainB/' + '-'.join(a.split('/')[-3:]), im_ext_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb340168",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-10T11:15:28.101Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "a_pth = 'data/oulucasia-ranked-aligned/trainA/'\n",
    "b_pth = 'data/oulucasia-ranked-aligned/trainB/'\n",
    "\n",
    "for imA, imB in zip(sorted(os.listdir(a_pth)), sorted(os.listdir(b_pth))):\n",
    "    imgA = cv2.imread(a_pth + imA)\n",
    "    imgB = cv2.cvtColor(cv2.imread(b_pth + imB), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    display(Image.fromarray(np.concatenate([imgA, imgB], axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d535c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Splitting cleaned extracted faces to train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6873577",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T09:10:15.560259Z",
     "start_time": "2023-12-09T09:10:15.511307Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fb22bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T09:09:13.993455Z",
     "start_time": "2023-12-09T09:09:13.943394Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0d549",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T10:12:34.773406Z",
     "start_time": "2023-12-09T10:12:21.574173Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# load images\n",
    "with open('ratings_merged_first_place.json') as f:\n",
    "    rat_dict = json.load(f)\n",
    "\n",
    "\n",
    "# create a dict by patients, emotions\n",
    "im_dict = {}\n",
    "for im_name in rat_dict['ratings']:\n",
    "    # skip nonimages andimages with rating less than 1\n",
    "    if im_name[-5:] != '.jpeg' or int(rat_dict['ratings'][im_name][0]) > 1:\n",
    "        continue\n",
    "    \n",
    "    patient = im_name.split('-')[0]\n",
    "    emotion = im_name.split('-')[1]\n",
    "    img_id = im_name.split('-')[2]\n",
    "    \n",
    "    if patient not in list(im_dict.keys()):\n",
    "        im_dict[patient] = {}\n",
    "    if emotion not in list(im_dict[patient].keys()):\n",
    "        im_dict[patient][emotion] = {}\n",
    "    im_dict[patient][emotion][img_id] = rat_dict['ratings'][im_name]\n",
    "    \n",
    "# split to train, test, val\n",
    "train_imgs_ratio = 0.65\n",
    "test_imgs_ratio = 0.2\n",
    "val_imgs_ratio = 0.15\n",
    "splits = {\"train_vl\": [],\"train_ni\": [], 'test_vl': [], \"test_ni\": [], \"val_vl\": [], \"val_ni\": []}\n",
    "for pt in im_dict.keys():\n",
    "    for em in im_dict[pt].keys():\n",
    "        imgs = im_dict[pt][em].keys()\n",
    "        \n",
    "        # get toal number of images for this folder\n",
    "        train_imgs = int(train_imgs_ratio * len(imgs))\n",
    "        test_imgs = int(test_imgs_ratio * len(imgs))\n",
    "        val_imgs = int(val_imgs_ratio * len(imgs))\n",
    "\n",
    "        # sample images\n",
    "        _train = random.sample(list(im_dict[pt][em].keys()), train_imgs)\n",
    "        splits['train_vl'] += [im_dict[pt][em][i][1] for i in _train]\n",
    "        splits['train_ni'] += [im_dict[pt][em][i][2] for i in _train]\n",
    "        _test = random.sample(list(set(im_dict[pt][em].keys()) - set(_train)), test_imgs)\n",
    "        splits['test_vl'] += [im_dict[pt][em][i][1] for i in _test]\n",
    "        splits['test_ni'] += [im_dict[pt][em][i][2] for i in _test]\n",
    "        _val = random.sample(list(set(im_dict[pt][em].keys()) - set(_train) - set(_test)), val_imgs)\n",
    "        splits['val_vl'] += [im_dict[pt][em][i][1] for i in _val]\n",
    "        splits['val_ni'] += [im_dict[pt][em][i][2] for i in _val]\n",
    "\n",
    "# save images to the folder\n",
    "target_folder = Path(\"data/X-oulucasia-ranked-aligned-splitted/\")\n",
    "source_fp = \"data/oulucasia-ranked-aligned\"\n",
    "for t, t2 in zip(splits['train_vl'], splits['train_ni']):\n",
    "   \n",
    "    if not Path(t).exists() or not Path(t2).exists():\n",
    "        continue\n",
    "    new_fp = target_folder / \"A\" / \"train\" / \"-\".join(Path(t).parts[-3:])\n",
    "    print(\"train vl\", t)\n",
    "    # Create all the possible directories and copy the file\n",
    "    new_fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy(Path(source_fp) / \"trainA\" / \"-\".join(Path(t).parts[-3:]), new_fp)\n",
    "\n",
    "    new_fp = target_folder / \"B\" / \"train\" / \"-\".join(Path(t2).parts[-3:])\n",
    "    print(\"train ni\", t2)\n",
    "    # Create all the possible directories and copy the file\n",
    "    new_fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy(Path(source_fp) / \"trainB\" / \"-\".join(Path(t2).parts[-3:]), new_fp)\n",
    "for t, t2 in zip(splits['test_vl'], splits['test_ni']):\n",
    "    if not Path(t).exists() or not Path(t2).exists():\n",
    "        continue\n",
    "    new_fp = target_folder / \"A\" / \"test\" / \"-\".join(Path(t).parts[-3:])\n",
    "    print('test vl',t)\n",
    "    # Create all the possible directories and copy the file\n",
    "    new_fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy(Path(source_fp) / \"trainA\" / \"-\".join(Path(t).parts[-3:]), new_fp)\n",
    "    \n",
    "    new_fp = target_folder / \"B\" / \"test\" / \"-\".join(Path(t2).parts[-3:])\n",
    "    print('test ni',t2)\n",
    "    # Create all the possible directories and copy the file\n",
    "    new_fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy(Path(source_fp) / \"trainB\" / \"-\".join(Path(t2).parts[-3:]), new_fp)\n",
    "for t, t2 in zip(splits['val_vl'], splits['val_ni']):\n",
    "    if not Path(t).exists() or not Path(t2).exists():\n",
    "        continue\n",
    "    new_fp = target_folder / \"A\" / \"val\" /\"-\".join(Path(t).parts[-3:])\n",
    "    print('val vl', t)\n",
    "    # Create all the possible directories and copy the file\n",
    "    new_fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy(Path(source_fp) / \"trainA\" / \"-\".join(Path(t).parts[-3:]), new_fp)\n",
    "\n",
    "    new_fp = target_folder / \"B\" / \"val\" / \"-\".join(Path(t2).parts[-3:])\n",
    "    print('val ni' , t2)\n",
    "    # Create all the possible directories and copy the file\n",
    "    new_fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy(Path(source_fp) / \"trainB\" / \"-\".join(Path(t2).parts[-3:]), new_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2209dc8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## _Exploring various possibliities of aligning faces_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a70fa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T14:45:27.533201Z",
     "start_time": "2023-12-10T14:44:57.825031Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "from retinaface import RetinaFace\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import dlib\n",
    "from deepface import DeepFace\n",
    "\n",
    "predictor_path = \"notebooks/shape_predictor_81_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb255be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T14:45:27.540420Z",
     "start_time": "2023-12-10T14:45:27.535717Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_crosses_on_image(image, points, color=(255, 0, 0), size=3, thickness=1):\n",
    "    for point in points:\n",
    "        x = int(point[0])\n",
    "        y = int(point[1])\n",
    "        \n",
    "        image = cv2.line(image, (x - size, y), (x + size, y), color, thickness)\n",
    "        image = cv2.line(image, (x, y - size), (x, y + size), color, thickness)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed067db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T15:03:04.858935Z",
     "start_time": "2023-12-10T14:54:41.072072Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from deepface import DeepFace\n",
    "\n",
    "with open('ratings_merged_first_place.json') as f:\n",
    "    rat_dict = json.load(f)\n",
    "print(\"Summary of ratings:\")\n",
    "ratings = rat_dict['ratings']\n",
    "summary = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "for k, (rating, a, b) in enumerate(list(ratings.values())):\n",
    "    if k % 20 != 0:\n",
    "        continue\n",
    "    \n",
    "    if a[-2:] == 'db':\n",
    "        continue\n",
    "    \n",
    "    summary[int(rating)] += 1\n",
    "    if int(rating) == 1:\n",
    "        im_a = cv2.imread(a)\n",
    "        im_b = cv2.imread(b)\n",
    "        \n",
    "        print(a)\n",
    "        print(b)\n",
    "        if im_a is None or im_b is None:\n",
    "            continue\n",
    "        \n",
    "        im_b = cv2.cvtColor(im_b, cv2.COLOR_BGR2RGB)\n",
    "        im_ext_b = DeepFace.extract_faces(im_b, (224, 224), detector_backend='retinaface', align=False, enforce_detection=True)\n",
    "        im_ext_a = DeepFace.extract_faces(im_a, (224, 224), detector_backend='retinaface', align=False, enforce_detection=True)\n",
    "        im_ext_b = cv2.cvtColor((255 * im_ext_b[0]['face']).astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
    "        im_ext_a = (255 * im_ext_a[0]['face']).astype(np.uint8)\n",
    "        \n",
    "#         display(Image.fromarray(np.concatenate([im_a, im_b], axis=1 )))\n",
    "#         display(Image.fromarray(np.concatenate([im_ext_a, im_ext_b], axis=1 )))\n",
    "        \n",
    "        # --------------\n",
    "#         print((im_ext_b.shape[1], im_ext_b.shape[0]))\n",
    "        shape = predictor(im_ext_b, dlib.rectangle(0,0,im_ext_b.shape[1]-1, im_ext_b.shape[0]-1))#[(0,0), (im_ext_b.shape[1]-1, im_ext_b.shape[0]-1)])\n",
    "        dl_ni_landmarks = np.array([[shape.part(p).x, shape.part(p).y] for p in range(shape.num_parts)]).astype(int)\n",
    "#         dl_ni_landmarks = np.array([[shape.part(p).x, shape.part(p).y] for p in range(27,48)]).astype(int)\n",
    "        shape = predictor(im_ext_a, dlib.rectangle(0,0,im_ext_a.shape[1], im_ext_a.shape[0]))# [(0,0), (im_ext_a.shape[1], im_ext_a.shape[0])])\n",
    "        dl_vl_landmarks = np.array([[shape.part(p).x, shape.part(p).y] for p in range(shape.num_parts)]).astype(int)\n",
    "#         dl_vl_landmarks = np.array([[shape.part(p).x, shape.part(p).y] for p in range(27,48)]).astype(int)\n",
    "    \n",
    "        H, mask = cv2.findHomography(dl_ni_landmarks, dl_vl_landmarks)\n",
    "        dl_ni_img_new = cv2.warpPerspective(im_ext_b, H, (im_ext_b.shape[1],im_ext_b.shape[1]), borderValue=[0,0,0])\n",
    "        \n",
    "        img1 = np.copy(im_ext_a)\n",
    "        img2 = np.copy(dl_ni_img_new)\n",
    "        alpha = 0.5\n",
    "        dst = cv2.addWeighted(img1, alpha, img2, 1 - alpha, 0)\n",
    "        \n",
    "        display(Image.fromarray(np.concatenate([print_crosses_on_image(np.copy(dl_ni_img_new),dl_vl_landmarks),dl_ni_img_new,dst], axis=1)))\n",
    "        # --------------\n",
    "        \n",
    "        img1 = np.copy(im_ext_b)\n",
    "        img2 = np.copy(im_ext_a)\n",
    "\n",
    "#         gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "#         ret, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "\n",
    "        # Combine the two images with transparency\n",
    "        alpha = 0.7\n",
    "        dst = cv2.addWeighted(img1, alpha, img2, 1 - alpha, 0)\n",
    "\n",
    "#         display(Image.fromarray(dst))\n",
    "        display(Image.fromarray(np.concatenate([im_ext_a, im_ext_b, dst], axis=1 )))\n",
    "        \n",
    "        \n",
    "for rating, count in summary.items():\n",
    "    print(f\"Number of pairs with rating {rating}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654d6aec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T21:41:58.273954Z",
     "start_time": "2023-12-06T21:41:58.214357Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the two images\n",
    "img1 = cv2.imread('image1.jpg')\n",
    "img2 = cv2.imread('image2.jpg')\n",
    "\n",
    "# Compute the difference between the two images\n",
    "difference = cv2.subtract(img1, img2)\n",
    "\n",
    "# Create a mask by thresholding the difference image\n",
    "gray = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY)\n",
    "ret, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "\n",
    "# Highlight the differences between the two images\n",
    "img1[mask != 0] = [0, 0, 255]\n",
    "img2[mask != 0] = [0, 0, 255]\n",
    "\n",
    "# Combine the two images vertically\n",
    "combined = cv2.vconcat([img1, img2])\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('Comparison', combined)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvDIP",
   "language": "python",
   "name": "venvdip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
